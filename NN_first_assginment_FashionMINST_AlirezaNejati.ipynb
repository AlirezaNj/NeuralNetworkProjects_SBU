{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing necessary libraries"
      ],
      "metadata": {
        "id": "Kc7ePO6Kvrom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "eTC8u0esnYSo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download datasets and Transform images"
      ],
      "metadata": {
        "id": "Czu0KhLfv0dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I get the FashionMINST image data from the source. Then I split 20% of train-set as validation-set. \n",
        "The batch size is 100 that means 100 samples per batch to load."
      ],
      "metadata": {
        "id": "0cjTV2gAzq6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "trainset = datasets.FashionMNIST(\"./data\", download = True, train = True, transform = transform)\n",
        "testset = datasets.FashionMNIST(\"./data\", download = True, train = False, transform = transform)\n",
        "\n",
        "indexes = list(range(len(trainset)))\n",
        "np.random.shuffle(indexes)\n",
        "split_size = int(np.floor(0.2 * len(trainset)))\n",
        "train_sample = SubsetRandomSampler(indexes[:split_size])\n",
        "valid_sample = SubsetRandomSampler(indexes[split_size:])\n",
        "\n",
        "trainloader = DataLoader(trainset, sampler = train_sample, batch_size = 100)\n",
        "validloader = DataLoader(trainset, sampler = valid_sample, batch_size = 100)\n",
        "testloader = DataLoader(testset, batch_size = 100, shuffle = True)"
      ],
      "metadata": {
        "id": "NTqftKCVqYUc"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize a Batch of Training Data"
      ],
      "metadata": {
        "id": "Mc4JaH6XwXGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see some images and their labels from train dataset I use matplotlib."
      ],
      "metadata": {
        "id": "CNnlsmzo2FFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
        "images, labels = iter(trainloader).next()\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "for i in range(10):\n",
        "    ax = plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(np.squeeze(images[i]), cmap = 'gray')\n",
        "    ax.set_title(str(labels[i].item())+' - '+label_names[labels[i].item()])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "heZAPqVR1YAk",
        "outputId": "aeab1d65-6a09-4a8a-e56a-194b2a5260b2"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Network Architecture, train the network and test the trained model"
      ],
      "metadata": {
        "id": "gtuB-4SSwzgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the train and test methods"
      ],
      "metadata": {
        "id": "DaSfd9WXxV-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method will train the model. Forward and backward phases are implemented. At the end, train loss and validation loss are printed for each epoch."
      ],
      "metadata": {
        "id": "nl-jXHbB2i27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP_train(n_epochs, model, optimizer, criterion, early_stopper = None):\n",
        "  model.train()\n",
        "  \n",
        "  for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    for data, target in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "    for data, target in validloader:\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    train_loss = train_loss/len(trainloader.sampler)\n",
        "    valid_loss = valid_loss/len(validloader.sampler)\n",
        "\n",
        "    print('Epoch {} ---> Training Loss: {:.4f} \\tValidation Loss: {:.4f}'.format(epoch + 1, train_loss, valid_loss))\n",
        "    \n",
        "    if(early_stopper):\n",
        "      if early_stopper.early_stop(valid_loss): \n",
        "        print('Train stopped at epoch {}'.format(epoch+1))\n",
        "        break\n"
      ],
      "metadata": {
        "id": "7iD32R7C-e2k"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the traind model with test dataset and report the accuracy for each class and overall accuracy."
      ],
      "metadata": {
        "id": "6fZ7PHWN4MbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP_test(model, criterion):\n",
        "  model.eval()\n",
        "\n",
        "  class_correct = list(0. for i in range(10))\n",
        "  class_total = list(0. for i in range(10))\n",
        "\n",
        "  test_loss = 0.0\n",
        "  for data, target in testloader:\n",
        "      output = model(data)\n",
        "      loss = criterion(output, target)\n",
        "      test_loss += loss.item()*data.size(0)\n",
        "      pred = output.argmax(1)\n",
        "      correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "      for i in range(64):\n",
        "          label = target.data[i]\n",
        "          class_correct[label] += correct[i].item()\n",
        "          class_total[label] += 1\n",
        "\n",
        "  test_loss = test_loss/len(testloader.dataset)\n",
        "  print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "  for i in range(10):\n",
        "      if class_total[i] > 0:\n",
        "          print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "              str(i), 100 * class_correct[i] / class_total[i],\n",
        "              np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "          \n",
        "  print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "      100. * np.sum(class_correct) / np.sum(class_total),\n",
        "      np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "adVh1tAjQsGU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network with one hidden layer"
      ],
      "metadata": {
        "id": "xT7fENaMx0en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I start with a network that has one hidden layer. The input layer has 28 * 28 nuerons. becaus images have 28 * 28 pixels. I use ReLu as activation function and softmax for output layer."
      ],
      "metadata": {
        "id": "Vb83oaZu5ayx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NueralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NueralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.log_softmax(self.fc3(x), dim = 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yZCPWyADNQDi"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I train this simple model using:\n",
        "30 epochs, SGD optimizer, learning rate = 0.01 and crossEntropy as loss function. You can see the result of training by train losses per epochs. "
      ],
      "metadata": {
        "id": "mxNSxzB37WbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 30\n",
        "model = NueralNetwork()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "MLP_train(n_epochs, model, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpA501BoQm1S",
        "outputId": "4b23f8cc-7022-401d-8b0e-46b7649da04b"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ---> Training Loss: 2.2625 \tValidation Loss: 2.2089\n",
            "Epoch 2 ---> Training Loss: 2.1102 \tValidation Loss: 1.9683\n",
            "Epoch 3 ---> Training Loss: 1.7661 \tValidation Loss: 1.5655\n",
            "Epoch 4 ---> Training Loss: 1.4079 \tValidation Loss: 1.2786\n",
            "Epoch 5 ---> Training Loss: 1.1782 \tValidation Loss: 1.1047\n",
            "Epoch 6 ---> Training Loss: 1.0355 \tValidation Loss: 0.9965\n",
            "Epoch 7 ---> Training Loss: 0.9427 \tValidation Loss: 0.9195\n",
            "Epoch 8 ---> Training Loss: 0.8777 \tValidation Loss: 0.8684\n",
            "Epoch 9 ---> Training Loss: 0.8300 \tValidation Loss: 0.8225\n",
            "Epoch 10 ---> Training Loss: 0.7922 \tValidation Loss: 0.7905\n",
            "Epoch 11 ---> Training Loss: 0.7599 \tValidation Loss: 0.7655\n",
            "Epoch 12 ---> Training Loss: 0.7337 \tValidation Loss: 0.7408\n",
            "Epoch 13 ---> Training Loss: 0.7110 \tValidation Loss: 0.7188\n",
            "Epoch 14 ---> Training Loss: 0.6902 \tValidation Loss: 0.6996\n",
            "Epoch 15 ---> Training Loss: 0.6718 \tValidation Loss: 0.6811\n",
            "Epoch 16 ---> Training Loss: 0.6537 \tValidation Loss: 0.6709\n",
            "Epoch 17 ---> Training Loss: 0.6381 \tValidation Loss: 0.6510\n",
            "Epoch 18 ---> Training Loss: 0.6222 \tValidation Loss: 0.6414\n",
            "Epoch 19 ---> Training Loss: 0.6106 \tValidation Loss: 0.6328\n",
            "Epoch 20 ---> Training Loss: 0.5981 \tValidation Loss: 0.6130\n",
            "Epoch 21 ---> Training Loss: 0.5862 \tValidation Loss: 0.6145\n",
            "Epoch 22 ---> Training Loss: 0.5763 \tValidation Loss: 0.5933\n",
            "Epoch 23 ---> Training Loss: 0.5646 \tValidation Loss: 0.5820\n",
            "Epoch 24 ---> Training Loss: 0.5553 \tValidation Loss: 0.5779\n",
            "Epoch 25 ---> Training Loss: 0.5463 \tValidation Loss: 0.5677\n",
            "Epoch 26 ---> Training Loss: 0.5362 \tValidation Loss: 0.5621\n",
            "Epoch 27 ---> Training Loss: 0.5308 \tValidation Loss: 0.5561\n",
            "Epoch 28 ---> Training Loss: 0.5224 \tValidation Loss: 0.5454\n",
            "Epoch 29 ---> Training Loss: 0.5152 \tValidation Loss: 0.5611\n",
            "Epoch 30 ---> Training Loss: 0.5096 \tValidation Loss: 0.5504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I reach 80% accuracy as a first try!"
      ],
      "metadata": {
        "id": "sVeyO-Sv-Ih9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_test(model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1KNzAQ2qnlo",
        "outputId": "a893cfed-0401-490a-83c3-065477b903a6"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.570205\n",
            "\n",
            "Test Accuracy of     0: 81% (521/642)\n",
            "Test Accuracy of     1: 94% (599/636)\n",
            "Test Accuracy of     2: 56% (367/646)\n",
            "Test Accuracy of     3: 85% (550/646)\n",
            "Test Accuracy of     4: 88% (578/656)\n",
            "Test Accuracy of     5: 88% (549/620)\n",
            "Test Accuracy of     6: 29% (187/624)\n",
            "Test Accuracy of     7: 90% (584/644)\n",
            "Test Accuracy of     8: 93% (600/644)\n",
            "Test Accuracy of     9: 92% (593/642)\n",
            "\n",
            "Test Accuracy (Overall): 80% (5128/6400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using dropout technique"
      ],
      "metadata": {
        "id": "OXAjGRqh-s5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NueralNetwork1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NueralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = F.log_softmax(self.fc3(x), dim = 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PZCpl2u_AZOW"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = NueralNetwork()\n",
        "optimizer1 = optim.SGD(model1.parameters(), lr = 0.01)\n",
        "\n",
        "MLP_train(n_epochs, model1, optimizer1, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHC8cGWnNwqc",
        "outputId": "06d5d897-0890-4445-d50f-e20d63091859"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ---> Training Loss: 2.2563 \tValidation Loss: 2.1940\n",
            "Epoch 2 ---> Training Loss: 2.0742 \tValidation Loss: 1.9173\n",
            "Epoch 3 ---> Training Loss: 1.7206 \tValidation Loss: 1.5370\n",
            "Epoch 4 ---> Training Loss: 1.3862 \tValidation Loss: 1.2666\n",
            "Epoch 5 ---> Training Loss: 1.1648 \tValidation Loss: 1.0931\n",
            "Epoch 6 ---> Training Loss: 1.0233 \tValidation Loss: 0.9846\n",
            "Epoch 7 ---> Training Loss: 0.9299 \tValidation Loss: 0.9111\n",
            "Epoch 8 ---> Training Loss: 0.8670 \tValidation Loss: 0.8560\n",
            "Epoch 9 ---> Training Loss: 0.8215 \tValidation Loss: 0.8211\n",
            "Epoch 10 ---> Training Loss: 0.7860 \tValidation Loss: 0.7899\n",
            "Epoch 11 ---> Training Loss: 0.7584 \tValidation Loss: 0.7624\n",
            "Epoch 12 ---> Training Loss: 0.7347 \tValidation Loss: 0.7445\n",
            "Epoch 13 ---> Training Loss: 0.7142 \tValidation Loss: 0.7200\n",
            "Epoch 14 ---> Training Loss: 0.6941 \tValidation Loss: 0.7070\n",
            "Epoch 15 ---> Training Loss: 0.6765 \tValidation Loss: 0.6941\n",
            "Epoch 16 ---> Training Loss: 0.6594 \tValidation Loss: 0.6752\n",
            "Epoch 17 ---> Training Loss: 0.6437 \tValidation Loss: 0.6557\n",
            "Epoch 18 ---> Training Loss: 0.6303 \tValidation Loss: 0.6436\n",
            "Epoch 19 ---> Training Loss: 0.6156 \tValidation Loss: 0.6266\n",
            "Epoch 20 ---> Training Loss: 0.6004 \tValidation Loss: 0.6151\n",
            "Epoch 21 ---> Training Loss: 0.5891 \tValidation Loss: 0.6105\n",
            "Epoch 22 ---> Training Loss: 0.5766 \tValidation Loss: 0.6000\n",
            "Epoch 23 ---> Training Loss: 0.5654 \tValidation Loss: 0.5819\n",
            "Epoch 24 ---> Training Loss: 0.5543 \tValidation Loss: 0.5741\n",
            "Epoch 25 ---> Training Loss: 0.5456 \tValidation Loss: 0.5725\n",
            "Epoch 26 ---> Training Loss: 0.5357 \tValidation Loss: 0.5642\n",
            "Epoch 27 ---> Training Loss: 0.5290 \tValidation Loss: 0.5516\n",
            "Epoch 28 ---> Training Loss: 0.5197 \tValidation Loss: 0.5449\n",
            "Epoch 29 ---> Training Loss: 0.5122 \tValidation Loss: 0.5362\n",
            "Epoch 30 ---> Training Loss: 0.5061 \tValidation Loss: 0.5325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_test(model1, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJCYbVJ6N6ld",
        "outputId": "bc635390-9ba8-4ac5-ffd7-716035890085"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.553782\n",
            "\n",
            "Test Accuracy of     0: 78% (499/636)\n",
            "Test Accuracy of     1: 93% (620/660)\n",
            "Test Accuracy of     2: 62% (404/649)\n",
            "Test Accuracy of     3: 83% (512/614)\n",
            "Test Accuracy of     4: 75% (495/655)\n",
            "Test Accuracy of     5: 84% (529/627)\n",
            "Test Accuracy of     6: 52% (322/618)\n",
            "Test Accuracy of     7: 89% (573/643)\n",
            "Test Accuracy of     8: 92% (598/648)\n",
            "Test Accuracy of     9: 93% (609/650)\n",
            "\n",
            "Test Accuracy (Overall): 80% (5161/6400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Using dropout technique didn't change the accuracy of this model.*"
      ],
      "metadata": {
        "id": "GOyoFYVLFlmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network with two hidden layers"
      ],
      "metadata": {
        "id": "ki6Fxubp-dPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a hidden layer to the network and see the result."
      ],
      "metadata": {
        "id": "jGC6KG7l-Qv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NueralNetwork2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NueralNetwork2, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = F.log_softmax(self.fc4(x), dim = 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Ejz9GZB3A0nJ"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = NueralNetwork2()\n",
        "optimizer2 = optim.SGD(model2.parameters(), lr = 0.01)\n",
        "\n",
        "MLP_train(n_epochs, model2, optimizer2, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATCYLnbFCHMw",
        "outputId": "48ec01b5-2454-4e9a-c439-7a6f75e47325"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ---> Training Loss: 2.2965 \tValidation Loss: 2.2883\n",
            "Epoch 2 ---> Training Loss: 2.2753 \tValidation Loss: 2.2598\n",
            "Epoch 3 ---> Training Loss: 2.2312 \tValidation Loss: 2.1936\n",
            "Epoch 4 ---> Training Loss: 2.1233 \tValidation Loss: 2.0370\n",
            "Epoch 5 ---> Training Loss: 1.9035 \tValidation Loss: 1.7562\n",
            "Epoch 6 ---> Training Loss: 1.6140 \tValidation Loss: 1.5061\n",
            "Epoch 7 ---> Training Loss: 1.4182 \tValidation Loss: 1.3635\n",
            "Epoch 8 ---> Training Loss: 1.3016 \tValidation Loss: 1.2653\n",
            "Epoch 9 ---> Training Loss: 1.2123 \tValidation Loss: 1.1856\n",
            "Epoch 10 ---> Training Loss: 1.1371 \tValidation Loss: 1.1207\n",
            "Epoch 11 ---> Training Loss: 1.0848 \tValidation Loss: 1.0732\n",
            "Epoch 12 ---> Training Loss: 1.0298 \tValidation Loss: 1.0273\n",
            "Epoch 13 ---> Training Loss: 0.9899 \tValidation Loss: 0.9906\n",
            "Epoch 14 ---> Training Loss: 0.9596 \tValidation Loss: 0.9638\n",
            "Epoch 15 ---> Training Loss: 0.9258 \tValidation Loss: 0.9373\n",
            "Epoch 16 ---> Training Loss: 0.9040 \tValidation Loss: 0.9094\n",
            "Epoch 17 ---> Training Loss: 0.8787 \tValidation Loss: 0.8887\n",
            "Epoch 18 ---> Training Loss: 0.8609 \tValidation Loss: 0.8671\n",
            "Epoch 19 ---> Training Loss: 0.8372 \tValidation Loss: 0.8490\n",
            "Epoch 20 ---> Training Loss: 0.8265 \tValidation Loss: 0.8352\n",
            "Epoch 21 ---> Training Loss: 0.8066 \tValidation Loss: 0.8231\n",
            "Epoch 22 ---> Training Loss: 0.7932 \tValidation Loss: 0.8056\n",
            "Epoch 23 ---> Training Loss: 0.7763 \tValidation Loss: 0.7885\n",
            "Epoch 24 ---> Training Loss: 0.7573 \tValidation Loss: 0.7777\n",
            "Epoch 25 ---> Training Loss: 0.7492 \tValidation Loss: 0.7666\n",
            "Epoch 26 ---> Training Loss: 0.7422 \tValidation Loss: 0.7558\n",
            "Epoch 27 ---> Training Loss: 0.7238 \tValidation Loss: 0.7446\n",
            "Epoch 28 ---> Training Loss: 0.7161 \tValidation Loss: 0.7324\n",
            "Epoch 29 ---> Training Loss: 0.7067 \tValidation Loss: 0.7217\n",
            "Epoch 30 ---> Training Loss: 0.6999 \tValidation Loss: 0.7146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_test(model2, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmkU5lytCZux",
        "outputId": "9b494aeb-ab91-4ffb-c42c-8b43aeed49a5"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.652566\n",
            "\n",
            "Test Accuracy of     0: 82% (524/633)\n",
            "Test Accuracy of     1: 94% (581/614)\n",
            "Test Accuracy of     2: 63% (404/636)\n",
            "Test Accuracy of     3: 82% (533/647)\n",
            "Test Accuracy of     4: 72% (452/626)\n",
            "Test Accuracy of     5: 76% (486/639)\n",
            "Test Accuracy of     6: 14% (92/640)\n",
            "Test Accuracy of     7: 87% (575/658)\n",
            "Test Accuracy of     8: 91% (595/649)\n",
            "Test Accuracy of     9: 95% (630/658)\n",
            "\n",
            "Test Accuracy (Overall): 76% (4872/6400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for this problem model with one hidden layer is better than two layer model.\n",
        "adding layer increase the complexity of model that not required for this problem."
      ],
      "metadata": {
        "id": "STe0XAZNHOK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network with three hidden layers"
      ],
      "metadata": {
        "id": "jc6G1Ph6GuCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "try three hidden layers model to see effect of adding another layer."
      ],
      "metadata": {
        "id": "kw3esFcsHqtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NueralNetwork3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NueralNetwork3, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 32)\n",
        "        self.fc5 = nn.Linear(32, 10)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = self.dropout(F.relu(self.fc4(x)))\n",
        "        x = F.log_softmax(self.fc5(x), dim = 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7KL3CIr9Cp09"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = NueralNetwork3()\n",
        "optimizer3 = optim.SGD(model3.parameters(), lr = 0.01)\n",
        "\n",
        "MLP_train(n_epochs, model3, optimizer3, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAfBD3qdLez-",
        "outputId": "3605d3dc-0fd3-4712-959a-bdf35863af65"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ---> Training Loss: 2.3089 \tValidation Loss: 2.3069\n",
            "Epoch 2 ---> Training Loss: 2.3044 \tValidation Loss: 2.3030\n",
            "Epoch 3 ---> Training Loss: 2.3007 \tValidation Loss: 2.2993\n",
            "Epoch 4 ---> Training Loss: 2.2967 \tValidation Loss: 2.2952\n",
            "Epoch 5 ---> Training Loss: 2.2920 \tValidation Loss: 2.2898\n",
            "Epoch 6 ---> Training Loss: 2.2858 \tValidation Loss: 2.2820\n",
            "Epoch 7 ---> Training Loss: 2.2754 \tValidation Loss: 2.2685\n",
            "Epoch 8 ---> Training Loss: 2.2559 \tValidation Loss: 2.2403\n",
            "Epoch 9 ---> Training Loss: 2.2116 \tValidation Loss: 2.1721\n",
            "Epoch 10 ---> Training Loss: 2.1020 \tValidation Loss: 2.0149\n",
            "Epoch 11 ---> Training Loss: 1.9161 \tValidation Loss: 1.8110\n",
            "Epoch 12 ---> Training Loss: 1.7242 \tValidation Loss: 1.6404\n",
            "Epoch 13 ---> Training Loss: 1.5727 \tValidation Loss: 1.5114\n",
            "Epoch 14 ---> Training Loss: 1.4510 \tValidation Loss: 1.4050\n",
            "Epoch 15 ---> Training Loss: 1.3507 \tValidation Loss: 1.3288\n",
            "Epoch 16 ---> Training Loss: 1.2868 \tValidation Loss: 1.2742\n",
            "Epoch 17 ---> Training Loss: 1.2349 \tValidation Loss: 1.2309\n",
            "Epoch 18 ---> Training Loss: 1.2009 \tValidation Loss: 1.2011\n",
            "Epoch 19 ---> Training Loss: 1.1690 \tValidation Loss: 1.1675\n",
            "Epoch 20 ---> Training Loss: 1.1321 \tValidation Loss: 1.1468\n",
            "Epoch 21 ---> Training Loss: 1.1036 \tValidation Loss: 1.1190\n",
            "Epoch 22 ---> Training Loss: 1.0948 \tValidation Loss: 1.0953\n",
            "Epoch 23 ---> Training Loss: 1.0648 \tValidation Loss: 1.0777\n",
            "Epoch 24 ---> Training Loss: 1.0469 \tValidation Loss: 1.0572\n",
            "Epoch 25 ---> Training Loss: 1.0302 \tValidation Loss: 1.0372\n",
            "Epoch 26 ---> Training Loss: 1.0128 \tValidation Loss: 1.0269\n",
            "Epoch 27 ---> Training Loss: 0.9936 \tValidation Loss: 1.0115\n",
            "Epoch 28 ---> Training Loss: 0.9788 \tValidation Loss: 1.0028\n",
            "Epoch 29 ---> Training Loss: 0.9726 \tValidation Loss: 0.9874\n",
            "Epoch 30 ---> Training Loss: 0.9545 \tValidation Loss: 0.9817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_test(model3, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIHiVRidLiJD",
        "outputId": "9bed777c-aa46-4bfa-c3f2-1563aad745ac"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.877245\n",
            "\n",
            "Test Accuracy of     0: 77% (478/618)\n",
            "Test Accuracy of     1: 91% (584/635)\n",
            "Test Accuracy of     2: 71% (462/650)\n",
            "Test Accuracy of     3: 62% (397/633)\n",
            "Test Accuracy of     4: 36% (227/627)\n",
            "Test Accuracy of     5: 38% (242/626)\n",
            "Test Accuracy of     6:  8% (53/636)\n",
            "Test Accuracy of     7: 84% (565/666)\n",
            "Test Accuracy of     8: 91% (602/656)\n",
            "Test Accuracy of     9: 93% (613/653)\n",
            "\n",
            "Test Accuracy (Overall): 65% (4223/6400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I said adding layers would not help to improve the accuracy of the model in this problem."
      ],
      "metadata": {
        "id": "Mikr3VHqIg6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using early stopping criteria"
      ],
      "metadata": {
        "id": "Gz-QLsDxIDMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = np.inf\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "g5xRfPCKMjs5"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NueralNetwork()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "early_stopper = EarlyStopper(patience = 2)\n",
        "MLP_train(40, model, optimizer, criterion, early_stopper)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHGG7dM3SDgI",
        "outputId": "ff52c48d-fd8e-4329-905b-f9c7a9749a9f"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ---> Training Loss: 2.2688 \tValidation Loss: 2.2185\n",
            "Epoch 2 ---> Training Loss: 2.1325 \tValidation Loss: 2.0080\n",
            "Epoch 3 ---> Training Loss: 1.8103 \tValidation Loss: 1.5975\n",
            "Epoch 4 ---> Training Loss: 1.4196 \tValidation Loss: 1.2794\n",
            "Epoch 5 ---> Training Loss: 1.1751 \tValidation Loss: 1.0992\n",
            "Epoch 6 ---> Training Loss: 1.0295 \tValidation Loss: 0.9853\n",
            "Epoch 7 ---> Training Loss: 0.9338 \tValidation Loss: 0.9108\n",
            "Epoch 8 ---> Training Loss: 0.8681 \tValidation Loss: 0.8569\n",
            "Epoch 9 ---> Training Loss: 0.8196 \tValidation Loss: 0.8101\n",
            "Epoch 10 ---> Training Loss: 0.7822 \tValidation Loss: 0.7807\n",
            "Epoch 11 ---> Training Loss: 0.7519 \tValidation Loss: 0.7584\n",
            "Epoch 12 ---> Training Loss: 0.7258 \tValidation Loss: 0.7335\n",
            "Epoch 13 ---> Training Loss: 0.7031 \tValidation Loss: 0.7113\n",
            "Epoch 14 ---> Training Loss: 0.6825 \tValidation Loss: 0.6899\n",
            "Epoch 15 ---> Training Loss: 0.6626 \tValidation Loss: 0.6730\n",
            "Epoch 16 ---> Training Loss: 0.6454 \tValidation Loss: 0.6546\n",
            "Epoch 17 ---> Training Loss: 0.6289 \tValidation Loss: 0.6402\n",
            "Epoch 18 ---> Training Loss: 0.6120 \tValidation Loss: 0.6233\n",
            "Epoch 19 ---> Training Loss: 0.5992 \tValidation Loss: 0.6125\n",
            "Epoch 20 ---> Training Loss: 0.5849 \tValidation Loss: 0.6130\n",
            "Epoch 21 ---> Training Loss: 0.5723 \tValidation Loss: 0.5879\n",
            "Epoch 22 ---> Training Loss: 0.5610 \tValidation Loss: 0.5840\n",
            "Epoch 23 ---> Training Loss: 0.5508 \tValidation Loss: 0.5705\n",
            "Epoch 24 ---> Training Loss: 0.5394 \tValidation Loss: 0.5621\n",
            "Epoch 25 ---> Training Loss: 0.5308 \tValidation Loss: 0.5561\n",
            "Epoch 26 ---> Training Loss: 0.5238 \tValidation Loss: 0.5540\n",
            "Epoch 27 ---> Training Loss: 0.5153 \tValidation Loss: 0.5451\n",
            "Epoch 28 ---> Training Loss: 0.5092 \tValidation Loss: 0.5311\n",
            "Epoch 29 ---> Training Loss: 0.4997 \tValidation Loss: 0.5341\n",
            "Epoch 30 ---> Training Loss: 0.4963 \tValidation Loss: 0.5224\n",
            "Epoch 31 ---> Training Loss: 0.4914 \tValidation Loss: 0.5215\n",
            "Epoch 32 ---> Training Loss: 0.4840 \tValidation Loss: 0.5211\n",
            "Epoch 33 ---> Training Loss: 0.4783 \tValidation Loss: 0.5148\n",
            "Epoch 34 ---> Training Loss: 0.4750 \tValidation Loss: 0.5063\n",
            "Epoch 35 ---> Training Loss: 0.4684 \tValidation Loss: 0.5047\n",
            "Epoch 36 ---> Training Loss: 0.4656 \tValidation Loss: 0.4985\n",
            "Epoch 37 ---> Training Loss: 0.4601 \tValidation Loss: 0.4997\n",
            "Epoch 38 ---> Training Loss: 0.4565 \tValidation Loss: 0.4971\n",
            "Epoch 39 ---> Training Loss: 0.4531 \tValidation Loss: 0.4941\n",
            "Epoch 40 ---> Training Loss: 0.4511 \tValidation Loss: 0.4870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_test(model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m98h7ynpl_wP",
        "outputId": "e7641609-d274-4551-e453-53995fe3795b"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.510961\n",
            "\n",
            "Test Accuracy of     0: 81% (518/635)\n",
            "Test Accuracy of     1: 93% (588/627)\n",
            "Test Accuracy of     2: 67% (434/645)\n",
            "Test Accuracy of     3: 83% (530/637)\n",
            "Test Accuracy of     4: 76% (493/648)\n",
            "Test Accuracy of     5: 88% (595/673)\n",
            "Test Accuracy of     6: 56% (360/639)\n",
            "Test Accuracy of     7: 92% (577/624)\n",
            "Test Accuracy of     8: 90% (575/633)\n",
            "Test Accuracy of     9: 94% (605/639)\n",
            "\n",
            "Test Accuracy (Overall): 82% (5275/6400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using batch normalization"
      ],
      "metadata": {
        "id": "LSOdQbGXJe4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NueralNetwork4(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NueralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = F.log_softmax(self.fc3(x), dim = 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "o9JXgJdCgPmT"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = NueralNetwork()\n",
        "optimizer4 = optim.SGD(model4.parameters(), lr = 0.01)\n",
        "\n",
        "MLP_train(n_epochs, model4, optimizer4, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiNxXGZ5lgj-",
        "outputId": "fb90becc-874b-4365-abe6-6b2e07502a8e"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ---> Training Loss: 2.2656 \tValidation Loss: 2.2112\n",
            "Epoch 2 ---> Training Loss: 2.1065 \tValidation Loss: 1.9622\n",
            "Epoch 3 ---> Training Loss: 1.7512 \tValidation Loss: 1.5462\n",
            "Epoch 4 ---> Training Loss: 1.3871 \tValidation Loss: 1.2621\n",
            "Epoch 5 ---> Training Loss: 1.1633 \tValidation Loss: 1.0912\n",
            "Epoch 6 ---> Training Loss: 1.0217 \tValidation Loss: 0.9774\n",
            "Epoch 7 ---> Training Loss: 0.9258 \tValidation Loss: 0.9042\n",
            "Epoch 8 ---> Training Loss: 0.8588 \tValidation Loss: 0.8491\n",
            "Epoch 9 ---> Training Loss: 0.8108 \tValidation Loss: 0.8032\n",
            "Epoch 10 ---> Training Loss: 0.7720 \tValidation Loss: 0.7708\n",
            "Epoch 11 ---> Training Loss: 0.7422 \tValidation Loss: 0.7443\n",
            "Epoch 12 ---> Training Loss: 0.7155 \tValidation Loss: 0.7187\n",
            "Epoch 13 ---> Training Loss: 0.6922 \tValidation Loss: 0.6971\n",
            "Epoch 14 ---> Training Loss: 0.6709 \tValidation Loss: 0.6819\n",
            "Epoch 15 ---> Training Loss: 0.6525 \tValidation Loss: 0.6608\n",
            "Epoch 16 ---> Training Loss: 0.6352 \tValidation Loss: 0.6449\n",
            "Epoch 17 ---> Training Loss: 0.6193 \tValidation Loss: 0.6323\n",
            "Epoch 18 ---> Training Loss: 0.6048 \tValidation Loss: 0.6186\n",
            "Epoch 19 ---> Training Loss: 0.5915 \tValidation Loss: 0.6072\n",
            "Epoch 20 ---> Training Loss: 0.5781 \tValidation Loss: 0.5949\n",
            "Epoch 21 ---> Training Loss: 0.5692 \tValidation Loss: 0.5948\n",
            "Epoch 22 ---> Training Loss: 0.5572 \tValidation Loss: 0.5815\n",
            "Epoch 23 ---> Training Loss: 0.5470 \tValidation Loss: 0.5706\n",
            "Epoch 24 ---> Training Loss: 0.5381 \tValidation Loss: 0.5627\n",
            "Epoch 25 ---> Training Loss: 0.5300 \tValidation Loss: 0.5549\n",
            "Epoch 26 ---> Training Loss: 0.5224 \tValidation Loss: 0.5483\n",
            "Epoch 27 ---> Training Loss: 0.5171 \tValidation Loss: 0.5422\n",
            "Epoch 28 ---> Training Loss: 0.5103 \tValidation Loss: 0.5422\n",
            "Epoch 29 ---> Training Loss: 0.5040 \tValidation Loss: 0.5340\n",
            "Epoch 30 ---> Training Loss: 0.4980 \tValidation Loss: 0.5397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_test(model4, criterion)"
      ],
      "metadata": {
        "id": "zSFjopo0lqP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MLP_train_regularized(n_epochs, model, optimizer, criterion, regular_type):\n",
        "  model.train()\n",
        "  \n",
        "  for epoch in range(n_epochs):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    for data, target in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        if(regular_type == 1):\n",
        "          l1_lambda = 0.001\n",
        "          l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
        "          loss = loss + l1_lambda * l1_norm\n",
        "        elif(regular_type == 2):\n",
        "          l2_lambda = 0.001\n",
        "          l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
        "          loss = loss + l2_lambda * l2_norm\n",
        "        elif(regular_type == 3):\n",
        "          loss = loss + torch.norm(model.layer.weight, p = 2)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "    for data, target in validloader:\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    train_loss = train_loss/len(trainloader.sampler)\n",
        "    valid_loss = valid_loss/len(validloader.sampler)\n",
        "\n",
        "    print('Epoch {} ---> Training Loss: {:.4f} \\tValidation Loss: {:.4f}'.format(epoch + 1, train_loss, valid_loss))"
      ],
      "metadata": {
        "id": "cV0zX9-Jl6Ys"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NueralNetwork()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "MLP_train_regularized(n_epochs, model, optimizer, criterion, 1) #L1 regularization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMkVFuYlsEKB",
        "outputId": "540cda51-833e-4b2e-cf9c-18fb23fc22a2"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ---> Training Loss: 6.2779 \tValidation Loss: 2.2212\n",
            "Epoch 2 ---> Training Loss: 5.9184 \tValidation Loss: 2.0578\n",
            "Epoch 3 ---> Training Loss: 5.4486 \tValidation Loss: 1.7280\n",
            "Epoch 4 ---> Training Loss: 4.8911 \tValidation Loss: 1.3999\n",
            "Epoch 5 ---> Training Loss: 4.4306 \tValidation Loss: 1.1963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_test(model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI5bF1ZZs6mi",
        "outputId": "35e76d28-ff14-4a47-e749-3aa96006b664"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.202471\n",
            "\n",
            "Test Accuracy of     0: 83% (531/639)\n",
            "Test Accuracy of     1: 90% (581/639)\n",
            "Test Accuracy of     2: 70% (465/657)\n",
            "Test Accuracy of     3: 34% (219/635)\n",
            "Test Accuracy of     4: 33% (215/650)\n",
            "Test Accuracy of     5:  0% ( 6/619)\n",
            "Test Accuracy of     6:  8% (52/640)\n",
            "Test Accuracy of     7: 90% (591/656)\n",
            "Test Accuracy of     8: 90% (579/637)\n",
            "Test Accuracy of     9: 91% (576/628)\n",
            "\n",
            "Test Accuracy (Overall): 59% (3815/6400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NueralNetwork()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "MLP_train_regularized(n_epochs, model, optimizer, criterion, 2) #L2 regularization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gBIdOAVtcWo",
        "outputId": "2443734b-4548-4d17-8521-cc67e7ac33d7"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 ---> Training Loss: 6.2668 \tValidation Loss: 2.2000\n",
            "Epoch 2 ---> Training Loss: 5.8973 \tValidation Loss: 2.0373\n",
            "Epoch 3 ---> Training Loss: 5.4439 \tValidation Loss: 1.7480\n",
            "Epoch 4 ---> Training Loss: 4.9156 \tValidation Loss: 1.4333\n",
            "Epoch 5 ---> Training Loss: 4.4602 \tValidation Loss: 1.2333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_test(model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-z6dNwltjv_",
        "outputId": "777452da-c6b2-4706-f6e0-1b905677c421"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.238327\n",
            "\n",
            "Test Accuracy of     0: 81% (519/640)\n",
            "Test Accuracy of     1: 90% (601/661)\n",
            "Test Accuracy of     2: 15% (100/650)\n",
            "Test Accuracy of     3: 36% (219/606)\n",
            "Test Accuracy of     4: 82% (531/640)\n",
            "Test Accuracy of     5:  0% ( 3/645)\n",
            "Test Accuracy of     6:  3% (25/664)\n",
            "Test Accuracy of     7: 92% (592/641)\n",
            "Test Accuracy of     8: 81% (501/616)\n",
            "Test Accuracy of     9: 89% (570/637)\n",
            "\n",
            "Test Accuracy (Overall): 57% (3661/6400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NueralNetwork()\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "MLP_train_regularized(n_epochs, model, optimizer, criterion, 3) #type 3 regularization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "atDGFIB9tq0P",
        "outputId": "5cc22f70-d82f-4428-e006-451b0d719860"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-224-80dc45d26e36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mMLP_train_regularized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#type 3 regularization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-223-d7ebef86a0c4>\u001b[0m in \u001b[0;36mMLP_train_regularized\u001b[0;34m(n_epochs, model, optimizer, criterion, regular_type)\u001b[0m\n\u001b[1;32m     19\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2_lambda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ml2_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregular_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1208\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NueralNetwork' object has no attribute 'layer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0h3zQ7dktxXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}